{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and Torch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor creation operations\n",
    "Specify shape and dtype as arguments. Shape can be a single integer, or tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A vector of 10 ones\n",
    "torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A (3, 3) matrix of 0s as integers\n",
    "torch.zeros((3, 3), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9363,  0.3162,  0.7511, -1.3430],\n",
       "         [ 1.3663, -0.8448,  2.4356, -0.1408],\n",
       "         [ 1.0460, -0.0701, -1.4731, -1.2486],\n",
       "         [ 1.7917,  1.2577,  1.9010, -0.7319]],\n",
       "\n",
       "        [[-0.7655,  0.6201,  1.1122,  0.2268],\n",
       "         [-0.0203,  0.3423,  1.0897,  0.2429],\n",
       "         [-0.1350, -0.7531, -0.0595,  0.2128],\n",
       "         [ 0.6086,  0.9427, -0.8392,  0.4083]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A (2, 4, 4) tensor of numbers from standard normal distribution\n",
    "torch.randn((2, 4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor shapes\n",
    "- Row vector: (B, 1)\n",
    "- Feature matrix: (B, D)\n",
    "- Greyscale images: (B, W, H, 1)\n",
    "- RGB images: (B, W, H, 3)\n",
    "- Arbitrary images: (B, W, H, C)\n",
    "- Sequences of vectors: (B, L, D)\n",
    "\n",
    "Create tensors of random numbers that have the same shapes as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6147,  0.0427, -0.5562, -0.7068, -1.2642,  0.3802, -0.1313,  1.1799,\n",
       "          0.4505, -0.1525],\n",
       "        [ 1.8360, -0.9395,  1.2424,  2.0652, -0.2309,  0.0450, -2.3479, -0.2827,\n",
       "         -1.1999, -0.2158],\n",
       "        [-0.2493, -1.5048,  0.6128, -0.5287, -0.2175,  1.6820, -0.3587, -1.2516,\n",
       "         -0.1518,  0.5955],\n",
       "        [ 0.4771,  1.7978,  1.2441, -1.6271,  1.3185, -1.6270,  1.5288,  1.5141,\n",
       "          1.1025, -0.6128]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create a feature matrix with 4 examples whose feature size is 10\n",
    "torch.randn((4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2027, -1.1366,  0.7774],\n",
       "          [-0.2401, -0.7282,  0.8560],\n",
       "          [ 0.8691,  2.7668, -0.6636],\n",
       "          ...,\n",
       "          [ 1.3713, -0.0357,  0.7443],\n",
       "          [ 0.3781, -0.8476,  2.4250],\n",
       "          [ 0.9127,  0.9393,  0.6135]],\n",
       "\n",
       "         [[-0.7050,  1.9606,  1.3471],\n",
       "          [ 1.5946,  0.0950, -0.2133],\n",
       "          [-1.6131, -0.2609, -0.5743],\n",
       "          ...,\n",
       "          [-0.7657, -0.1005, -1.7460],\n",
       "          [ 1.0679, -0.6975, -0.4910],\n",
       "          [ 1.3332,  0.1012, -0.0114]],\n",
       "\n",
       "         [[ 2.3520,  2.8420, -1.6052],\n",
       "          [ 0.2768,  0.0233, -1.4937],\n",
       "          [-1.5348, -0.3646,  0.5498],\n",
       "          ...,\n",
       "          [-0.4312,  0.6737,  1.3217],\n",
       "          [ 0.1892, -0.5117,  0.7452],\n",
       "          [-0.8440, -2.1202, -1.1583]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.9878,  1.0099, -1.0879],\n",
       "          [ 0.5793,  1.5808,  0.4065],\n",
       "          [ 0.7270, -0.8774, -0.3284],\n",
       "          ...,\n",
       "          [ 0.4045,  0.3647,  0.4277],\n",
       "          [ 0.5701, -0.4057,  0.5278],\n",
       "          [-0.3150,  0.2574,  0.0390]],\n",
       "\n",
       "         [[-1.5136, -0.3689, -0.1718],\n",
       "          [-0.0503,  0.8418,  1.3287],\n",
       "          [-1.8448, -0.8448,  0.6819],\n",
       "          ...,\n",
       "          [ 0.0304, -2.0440, -0.6934],\n",
       "          [-1.1047, -0.2089, -1.3188],\n",
       "          [-0.3010, -0.2552,  0.1534]],\n",
       "\n",
       "         [[ 0.0369,  0.3615,  1.2104],\n",
       "          [ 0.8894, -0.3694, -1.0132],\n",
       "          [ 0.1722,  0.5323,  0.5046],\n",
       "          ...,\n",
       "          [ 0.4095,  0.7209,  1.5928],\n",
       "          [-0.4829, -0.1859, -0.4318],\n",
       "          [ 0.9285,  1.1018,  0.0250]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4845, -1.0206,  0.8296],\n",
       "          [-0.5262, -1.0924,  0.6687],\n",
       "          [ 1.1622, -1.4084,  0.7367],\n",
       "          ...,\n",
       "          [-0.0825,  0.1739,  0.6032],\n",
       "          [ 0.4366,  1.6661, -1.1647],\n",
       "          [ 0.6064,  0.5680, -0.8408]],\n",
       "\n",
       "         [[ 0.4946, -0.2049,  0.3818],\n",
       "          [ 0.5502, -0.4471,  0.0596],\n",
       "          [ 0.1029, -1.0378, -0.2754],\n",
       "          ...,\n",
       "          [-0.6735, -0.8084, -1.0483],\n",
       "          [ 0.8610,  0.2034,  0.0105],\n",
       "          [ 0.8450, -0.1645,  1.3631]],\n",
       "\n",
       "         [[ 1.0265, -0.9701, -0.8752],\n",
       "          [ 1.1151, -1.7182,  0.0447],\n",
       "          [ 0.2009, -1.9928,  0.2760],\n",
       "          ...,\n",
       "          [ 0.9854, -0.1954,  0.4583],\n",
       "          [-0.7667, -0.3691,  0.1933],\n",
       "          [ 1.4660, -0.8723, -0.6269]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0626, -1.1329,  2.1141],\n",
       "          [ 0.7029,  0.2622, -1.0770],\n",
       "          [ 0.2360,  0.1734,  0.8018],\n",
       "          ...,\n",
       "          [ 0.9738,  0.3840,  0.1357],\n",
       "          [ 0.3895, -0.7356,  2.8037],\n",
       "          [-0.6953,  0.9099,  0.5098]],\n",
       "\n",
       "         [[ 1.1554, -0.1573, -1.1326],\n",
       "          [ 0.3468, -0.1557,  0.9229],\n",
       "          [ 1.7605,  1.0466, -1.1074],\n",
       "          ...,\n",
       "          [-0.7911,  1.0383,  0.9001],\n",
       "          [-1.8787,  0.2015, -0.6911],\n",
       "          [-0.8788,  1.1557, -0.2570]],\n",
       "\n",
       "         [[ 1.0915,  0.6515, -1.9854],\n",
       "          [-0.6934,  1.2386,  0.8726],\n",
       "          [ 0.0908,  0.2688,  1.8293],\n",
       "          ...,\n",
       "          [ 0.9046, -0.2886,  0.8002],\n",
       "          [-0.8557,  0.5435, -0.4816],\n",
       "          [ 1.2872, -0.4610, -1.4130]]],\n",
       "\n",
       "\n",
       "        [[[-1.7091, -0.1874,  0.0044],\n",
       "          [-0.7610,  0.2311,  0.4231],\n",
       "          [-0.0586, -0.8161, -0.7993],\n",
       "          ...,\n",
       "          [-0.1960, -0.5171,  0.2689],\n",
       "          [-1.7256, -0.7459,  1.0724],\n",
       "          [ 0.0936,  1.2830, -0.7585]],\n",
       "\n",
       "         [[ 0.2844, -0.6121, -0.0559],\n",
       "          [ 0.5652, -0.6636, -0.0055],\n",
       "          [ 0.3629, -2.4398,  0.6292],\n",
       "          ...,\n",
       "          [ 0.8494,  0.2004,  1.2383],\n",
       "          [-1.6928,  0.5004, -0.5723],\n",
       "          [-0.3035, -0.3969,  0.2023]],\n",
       "\n",
       "         [[ 0.3396,  0.4578, -0.8203],\n",
       "          [ 0.3652,  0.2250, -0.3769],\n",
       "          [-0.6259, -0.6125,  1.2213],\n",
       "          ...,\n",
       "          [ 1.9493,  0.6917, -0.2546],\n",
       "          [-0.6668,  1.4644, -0.5526],\n",
       "          [ 0.7942, -0.1652, -0.6126]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3492,  1.1774, -0.5559],\n",
       "          [ 1.6811, -1.8760, -0.3423],\n",
       "          [ 0.8669,  0.7086, -1.1010],\n",
       "          ...,\n",
       "          [-0.9100, -0.3968,  2.0616],\n",
       "          [ 1.3304, -0.4287,  0.4489],\n",
       "          [ 0.4937,  0.7285, -0.7300]],\n",
       "\n",
       "         [[-0.8243, -0.1397,  1.2582],\n",
       "          [ 0.5973,  0.6039, -1.1924],\n",
       "          [-1.5919, -1.2782, -0.4861],\n",
       "          ...,\n",
       "          [ 0.8442,  1.5364, -0.8369],\n",
       "          [-0.3066, -0.3874,  0.7102],\n",
       "          [ 0.1266, -0.7480, -0.6072]],\n",
       "\n",
       "         [[ 1.7920,  0.5489,  0.7315],\n",
       "          [-0.1987, -1.6121,  0.9849],\n",
       "          [-0.0556,  0.2579,  0.8552],\n",
       "          ...,\n",
       "          [ 0.1034,  0.5497,  1.5272],\n",
       "          [-1.1402, -1.3023,  0.0839],\n",
       "          [ 1.0181,  1.6403, -1.4908]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1560,  1.4969,  0.8743],\n",
       "          [-0.7260, -0.2146,  0.7088],\n",
       "          [ 0.7307, -1.1508, -0.9631],\n",
       "          ...,\n",
       "          [ 0.7589, -0.1237, -1.0893],\n",
       "          [ 1.0306,  0.7374,  0.2323],\n",
       "          [ 0.1236,  0.0429, -0.1235]],\n",
       "\n",
       "         [[ 0.3187,  0.1105, -1.3183],\n",
       "          [ 0.3895,  0.2108,  0.1892],\n",
       "          [ 1.5912, -0.8985,  0.4778],\n",
       "          ...,\n",
       "          [ 0.6481,  1.3242, -0.6138],\n",
       "          [-0.6055,  1.0017, -1.2168],\n",
       "          [-1.3448,  1.3677,  1.8159]],\n",
       "\n",
       "         [[ 0.7336, -1.4871,  0.3398],\n",
       "          [ 0.9495, -1.4994, -0.3758],\n",
       "          [-2.1504, -0.9052, -0.5029],\n",
       "          ...,\n",
       "          [ 0.5304, -0.2646, -2.2877],\n",
       "          [-0.5852, -0.0715,  1.2728],\n",
       "          [ 1.9470, -0.4512,  0.9164]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2281, -1.2625,  0.6242],\n",
       "          [-0.6316, -0.1598, -1.1681],\n",
       "          [ 0.3472,  0.8323, -0.6769],\n",
       "          ...,\n",
       "          [ 0.8593, -0.7662,  0.6704],\n",
       "          [-3.4203, -1.6420,  1.2692],\n",
       "          [ 1.1809, -0.0420, -1.0145]],\n",
       "\n",
       "         [[-1.2472,  0.4917,  0.2800],\n",
       "          [-1.2668, -0.1937,  1.2131],\n",
       "          [ 1.0938,  1.0779,  0.6143],\n",
       "          ...,\n",
       "          [ 0.1286,  0.1942, -0.1321],\n",
       "          [-1.5325,  0.9096,  1.0623],\n",
       "          [-1.3662, -1.2129, -0.0796]],\n",
       "\n",
       "         [[-0.2965, -0.3442,  1.5154],\n",
       "          [ 1.3681, -0.1568,  2.1905],\n",
       "          [-1.3030,  0.8575, -1.4632],\n",
       "          ...,\n",
       "          [-1.4142,  0.1249, -1.3483],\n",
       "          [ 0.1152,  1.5439, -1.9021],\n",
       "          [ 1.1809,  1.0650, -0.1514]]],\n",
       "\n",
       "\n",
       "        [[[-0.2131,  0.7337, -0.6709],\n",
       "          [ 0.1429,  0.0244, -0.1140],\n",
       "          [-0.0707, -1.6306,  0.9039],\n",
       "          ...,\n",
       "          [-1.4575, -0.2607,  0.1429],\n",
       "          [ 1.5038, -0.9972, -1.5494],\n",
       "          [-0.2139,  0.3637, -0.3499]],\n",
       "\n",
       "         [[-1.6355, -0.1271, -1.6054],\n",
       "          [ 2.5890, -0.1098,  0.0619],\n",
       "          [ 0.7323, -1.0678, -1.2937],\n",
       "          ...,\n",
       "          [-0.8202, -0.6158, -1.5987],\n",
       "          [-1.2624,  0.7441,  0.7917],\n",
       "          [-0.6214,  0.4916, -0.2329]],\n",
       "\n",
       "         [[ 0.2902, -1.7528,  0.4975],\n",
       "          [ 1.2156, -1.0142, -0.6488],\n",
       "          [ 0.8284, -0.0080, -0.1152],\n",
       "          ...,\n",
       "          [ 0.3136,  1.1652, -0.6082],\n",
       "          [ 0.8749,  1.6618, -0.5965],\n",
       "          [-1.2556, -0.0444,  0.3488]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.8347, -0.7241,  1.1055],\n",
       "          [ 0.1137, -0.3965, -0.9025],\n",
       "          [ 1.7570,  0.0389,  0.8143],\n",
       "          ...,\n",
       "          [ 0.6505,  0.4090,  0.9079],\n",
       "          [-0.0070,  0.6699,  1.6263],\n",
       "          [ 0.6752, -1.3448,  0.2834]],\n",
       "\n",
       "         [[-0.9359,  0.0714, -0.7079],\n",
       "          [-1.8008, -0.1563,  0.5366],\n",
       "          [-1.4299,  0.6396, -1.3567],\n",
       "          ...,\n",
       "          [ 0.7403, -0.3681, -0.6895],\n",
       "          [-1.3547,  0.6550, -0.4754],\n",
       "          [-2.0504, -1.4345,  0.3155]],\n",
       "\n",
       "         [[ 0.9012,  0.5300,  0.6046],\n",
       "          [-1.5700, -0.1510, -1.0009],\n",
       "          [ 0.5504, -0.6459, -0.0044],\n",
       "          ...,\n",
       "          [ 0.8833, -1.8170, -0.0797],\n",
       "          [-0.0039,  1.7193,  0.9501],\n",
       "          [-0.2619, -0.9811, -1.7290]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create a batch of 5 RGB images whose spatial dimensions are 32x32\n",
    "torch.randn((5, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7008, -0.2929,  0.5752,  0.8768],\n",
       "         [-0.6764,  1.4848, -0.9929, -1.0976],\n",
       "         [-0.8327,  2.1122, -0.6767,  0.9652],\n",
       "         [ 0.7174,  0.5985, -0.3428, -0.8498],\n",
       "         [-1.9296,  1.1661, -0.7060,  0.0589],\n",
       "         [-0.2921, -0.1822,  0.7908, -0.6844],\n",
       "         [-0.4218,  0.7073,  0.4393,  1.0033]],\n",
       "\n",
       "        [[ 0.0109,  0.3343, -0.3397,  0.4333],\n",
       "         [-0.1683, -0.2709,  0.9795,  0.2638],\n",
       "         [ 0.6140,  0.4783,  0.3305,  1.3098],\n",
       "         [-1.1850, -1.3816, -0.3515,  1.5610],\n",
       "         [ 0.5919,  0.8282,  0.2370, -0.3555],\n",
       "         [-1.6616, -1.5484, -1.1998,  2.1987],\n",
       "         [ 1.6813, -2.1308, -1.0748, -1.8396]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create a batch of 2 vector sequences, whose sequence lengths are 7 and feature dimension is 4\n",
    "torch.randn((2, 7, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch dtypes\n",
    "Some useful conversions:\n",
    "- `torch.FloatTensor()` can be used to create tensors of `torch.float32` dtype\n",
    "- `torch.LongTensor()` can be used to create tensors of `torch.int64` dtype\n",
    "- Numpy arrays can be converted with `torch.from_numpy(x)`\n",
    "- `dtype` can be specified in some creation operations\n",
    "- Tensors can be cast using `x.type(new_type)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor indexing\n",
    "\n",
    "A tensor dimension of size D can be indexed in the following ways:\n",
    "- Single integers from [0, D-1] or [-D, -1] for reverse indices\n",
    "- Lists of integers or tensors of integer dtypes\n",
    "- Slices, using colon notation, or slice objects\n",
    "- Boolean masks of size D (or broadcastable)\n",
    "- Ellipsis to infer other dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(12)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(11), tensor(9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single integer indexing\n",
    "a[1], a[-1], a[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3, 5]), tensor([2, 2, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List indexing\n",
    "a[[1, 3, 5]], a[[2, 2, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single colon represents entire dim, here we select all of row 0\n",
    "b = a.reshape(3, 4)\n",
    "b, b[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]),\n",
       " tensor([0, 1, 2, 3, 4]),\n",
       " tensor([ 5,  6,  7,  8,  9, 10, 11]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colons can represent ranges by `start:end`, exclusive of end when specified. Infers beginning or end\n",
    "a[0:3], a[:5], a[5:], a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]),\n",
       " tensor([ True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean masks can be used to select based on conditions\n",
    "mask = a < 5\n",
    "a[mask], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39]],\n",
       " \n",
       "         [[40, 41, 42, 43, 44],\n",
       "          [45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]]]),\n",
       " tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ellipsis can infer dimensions\n",
    "c = torch.arange(60).reshape(3, 4, 5)\n",
    "c, c[0, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply relu to tensor `a` and print results\n",
    "a = torch.arange(-5, 5)\n",
    "a = torch.relu(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "Broadcasting rules:\n",
    "- Right-most dimensions matches\n",
    "- A dimension has size 1 (including scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We would expect without broadcasting to apply all operations elementwise with operands of the same size\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([10, 10, 10])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 12., 13.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Broadcasting to add a scalar to a tensor\n",
    "a + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,  11., 102., 203.],\n",
       "        [  5.,  15., 106., 207.],\n",
       "        [  9.,  19., 110., 211.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Adding a vector to each row of a matrix\n",
    "a = torch.arange(12).reshape(3, 4)  # Matrix of size (3, 4)\n",
    "b = torch.Tensor([1, 10, 100, 200])  # Column vector of size (4,)\n",
    "# Sizes: (3, 4) + (4,)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Creating a boolean mask from a tensor\n",
    "a = torch.arange(12).reshape(3, 4)\n",
    "a < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Adding a tensor that has a singleton dimension\n",
    "a = torch.randn((2, 4, 3, 10))\n",
    "b = torch.randn((4, 1, 10))\n",
    "# (2, 4, 3, 10)\n",
    "#    (4, 1, 10)\n",
    "# =============\n",
    "# (2, 4, 3, 10)\n",
    "\n",
    "# Note that b with shape (4, 10) will not broadcast\n",
    "# b = torch.randn((4, 10))\n",
    "\n",
    "c = a + b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.1315,   4.6295, 117.7399],\n",
       "        [ -3.1945,   5.5485, 104.2687],\n",
       "        [ -3.1407,   6.0279,  94.9768],\n",
       "        [ -3.0268,   4.0486, 100.5392],\n",
       "        [ -2.8424,   4.9274,  74.5696],\n",
       "        [ -2.8274,   4.8226,  95.3272],\n",
       "        [ -3.0609,   4.3686,  96.3954],\n",
       "        [ -2.9339,   4.3351, 110.9736],\n",
       "        [ -3.0475,   4.1226,  92.2756],\n",
       "        [ -3.0088,   4.6285,  97.4372]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Transform a random normal tensor of shape (3, 10)\n",
    "# The columns should have means of [-3, 5, 100] and standard deviations of [0.1, 1, 10]\n",
    "a = torch.randn((10, 3))  # Shape     (10, 3)\n",
    "means = torch.Tensor([-3, 5, 100])  #     (3,)\n",
    "stds = torch.Tensor([0.1, 1, 10])   #     (3,)\n",
    "(a * stds) + means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "Matmul rules:\n",
    "- A has shape `(..., l, m)`\n",
    "- B has shape `     (m, n)`\n",
    "- Last dimension of A must have same as second-last dimension of B\n",
    "- Transform last dimension of A from `m` to `n`\n",
    "- Can use `torch.mm()` or `@` operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Multiply two matrices\n",
    "A = torch.randn((3, 5))\n",
    "B = torch.randn((5, 10))\n",
    "# (3, 5)  @ (5, 10) -> (3, 10)\n",
    "C = A @ B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 32, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Matmul can be broadcasted\n",
    "A = torch.randn((4, 32, 32, 3))\n",
    "B = torch.randn((3, 10))\n",
    "# (4, 32, 32, 3) @ (3, 10) -> (4, 32, 32, 10)\n",
    "C = A @ B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Transform this batch of vector sequences from feature size 7 to feature size 32 through matmul\n",
    "A = torch.randn(4, 100, 7)\n",
    "B = torch.randn(7, 32)\n",
    "# (4, 100, 7) @ (?, ?) -> (?, ?, ?)\n",
    "C = A @ B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction operations\n",
    "Reduction operation rules:\n",
    "- By default reduces across whole tensor\n",
    "- Specify the `dim` keyword to specify reduction dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(12).reshape(3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Sum all elements of a\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 15, 18, 21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Sum along rows (dim=0)\n",
    "a.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 22, 38])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Sum along columns\n",
    "a.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.7105, -0.2768, -0.5030, -0.0168,  0.3736,  0.4711,  0.0310,  0.6269,\n",
       "          0.0770, -0.0220]),\n",
       " tensor([0.8379, 1.5381, 1.1045, 1.3531, 0.6035, 1.0231, 0.7048, 1.0874, 0.5550,\n",
       "         0.9840]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compute the mean and standard deviation of this tensor along rows\n",
    "a = torch.randn((10, 4))\n",
    "a.mean(dim=1), a.std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape operations\n",
    "- `x.reshape(shape)`: Reshapes to `shape`, product of dims must be same before and after\n",
    "- `x.squeeze()`: Remove singleton dims\n",
    "- `x.unsqueeze(d)`: Add a singleton dim at dimension `d`\n",
    "- `x.flatten()`: Unravel into a vector of shape `(x.size,)`\n",
    "- `x.permute(order)`: Permute order of dims according to a tuple of dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19]]],\n",
       "\n",
       "\n",
       "        [[[20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [30, 31, 32, 33, 34],\n",
       "          [35, 36, 37, 38, 39]]],\n",
       "\n",
       "\n",
       "        [[[40, 41, 42, 43, 44],\n",
       "          [45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(60).reshape(3, 1, 4, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "         48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Reshape to (2, 30)\n",
    "a.reshape(2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Squeeze out extra dimension\n",
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59]),\n",
       " torch.Size([60]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Flatten into a vector\n",
    "a.flatten(), a.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Flatten just the last two dims\n",
    "a.flatten(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Permute order of dims\n",
    "# (3, 1, 4, 5)\n",
    "# (0, 1, 2, 3)\n",
    "# Permute to (1, 5, 4, 3)\n",
    "a.permute((1, 3, 2, 0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Process the logistic regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75, 4), numpy.ndarray)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"data/logistic-regression-data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "x = data[\"training_x\"]\n",
    "x.shape, type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([75, 4]), torch.float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Convert the data to a tensor in float32 dtype\n",
    "x = torch.from_numpy(x)\n",
    "x = x.type(torch.float32)\n",
    "x.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.2333, 2.8653, 4.8800, 1.6653]),\n",
       " tensor([0.6618, 0.3042, 0.8276, 0.4304]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compute the mean and std over the batch dimension\n",
    "mean = x.mean(dim=0)\n",
    "std = x.std(dim=0)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Standardize the data by subtracting the mean and dividing by std\n",
    "x = (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.3140e-07,  5.4042e-08, -1.7643e-07, -1.5736e-07]),\n",
       " tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Verify the new mean/std are standard normal\n",
    "x.mean(dim=0), x.std(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Linear layer\n",
    "The `torch.nn.Linear(m, n)` layer applies the equation `y = x @ w + b` such that `w` is a weight matrix of shape (m, n), `b` is a bias vector of length (n,) and takes `x` from shape (b, m) to `y` with shape (b, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply a Linear layer transformation to this feature matrix.\n",
    "# The resultant tensor, y, should have shape (100, 16)\n",
    "x = torch.randn(100, 32)\n",
    "w = torch.randn(32, 16)\n",
    "b = torch.randn(16)\n",
    "y = x @ w + b\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Convert a to shape that is compatible with this matmul to result in a tensor of shape (3, 5, 7)\n",
    "x = torch.randn(3, 4, 5)\n",
    "w = torch.randn(4, 7)\n",
    "b = torch.randn(7)\n",
    "x = x.permute((0, 2, 1))\n",
    "y = x @ w + b\n",
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
